{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.cluster.vq import vq\n",
    "\n",
    "# function to extract magnitude space vectors and angle space vectors\n",
    "# optical_flow_data_path: \n",
    "def extract_vec_points(optical_flow_data_path):\n",
    "    # Convert into magnitude space points and angle space points.\n",
    "    mag_vecs = []\n",
    "    ang_vecs = []\n",
    "    data = pickle.load(open(optical_flow_data_path,\"rb\"))\n",
    "    # Iterate over the videos contained in the dictionary\n",
    "    for k, v in data.iteritems():\n",
    "        # Iterate over the 2x16x12 dimensional matrices, for each flow feature\n",
    "        for flow_feature in v:\n",
    "            mag_vecs.append(flow_feature[0,...].ravel())\n",
    "            ang_vecs.append(flow_feature[1,...].ravel())\n",
    "        print(\"Video {} : Size_mag : {}\".format(k, len(mag_vecs)))\n",
    "    print(\"Done for {}\".format(optical_flow_data_path))\n",
    "    return np.array(mag_vecs), np.array(ang_vecs)\n",
    "\n",
    "\n",
    "# Form a magnitude and angle dataframes using extracted features kept in \n",
    "# feats_data_dict. BOW rows are calculated using counts of \n",
    "# Returns two dataframes of (nVids, nClusters). \n",
    "# assignment to one of the centroids.\n",
    "# feats_data_dict: {'filename':[array(2,16,12), array(2,16,12), ....]}\n",
    "def create_bovw_traindf(feats_data_dict, kmeans_mag, kmeans_ang, \\\n",
    "                        mag_min, mag_max, ang_min, ang_max, idfpath):\n",
    "    \n",
    "    clusters_mag = kmeans_mag.cluster_centers_\n",
    "    clusters_ang = kmeans_ang.cluster_centers_\n",
    "    vids_list = feats_data_dict.keys()\n",
    "    n_videos = len(vids_list)\n",
    "    \n",
    "    # Create a dataframe of size n_videos X n_clusters\n",
    "    print(\"Make bow vector for each frame\")\n",
    "    bow_mag = np.zeros((n_videos, clusters_mag.shape[0]))\n",
    "    bow_ang = np.zeros((n_videos, clusters_ang.shape[0]))\n",
    "    \n",
    "    print(\"Shape of bow_mag : {}\".format(bow_mag.shape))\n",
    "    print(\"Shape of bow_ang : {}\".format(bow_ang.shape))\n",
    "    \n",
    "    # Make bow vectors for all videos.\n",
    "    for video_index, video in enumerate(vids_list):\n",
    "        # Read the features from the dictionary and get the\n",
    "        frames_feats = feats_data_dict[video]\n",
    "        mag, ang = [], []\n",
    "        \n",
    "        # feat is an array(2,16,12)\n",
    "        mag = [feat[0,...].ravel() for feat in frames_feats]\n",
    "        ang = [feat[1,...].ravel() for feat in frames_feats]\n",
    "        mag = np.array(mag)  # (nFlowFrames, 192)\n",
    "        ang = np.array(ang)\n",
    "        # change inf values to 0\n",
    "        mag[np.isinf(mag)] = 0\n",
    "        ang[np.isinf(ang)] = 0\n",
    "            \n",
    "        ##### Normalize\n",
    "        mag = (mag - mag_min)/(mag_max - mag_min)\n",
    "        ang = (ang - ang_min)/(ang_max - ang_min)\n",
    "        # find cluster centroid assignments for all points\n",
    "        # returns a tuple, with first element having ids of the cluster centroid \n",
    "        # to which the row i belongs to. Second element is the distance between \n",
    "        # the nearest code and the ith row.\n",
    "        # visual_word_ids is a 1D array\n",
    "        word_ids_mag = vq(mag, clusters_mag)[0]  # ignoring the distances in [1]\n",
    "        word_ids_ang = vq(ang, clusters_ang)[0]  # ignoring the distances in [1]\n",
    "        for word_id in word_ids_mag:\n",
    "            bow_mag[video_index, word_id] += 1  \n",
    "        \n",
    "        for word_id in word_ids_ang:\n",
    "            bow_ang[video_index, word_id] += 1  \n",
    "        \n",
    "        print(\"Done video {} : {}\".format(video_index, video))\n",
    "    \n",
    "    print(\"Applying TF-IDF weighting\")\n",
    "    # This is applicable for only the training set\n",
    "    # For validation/test set, the idf will be same as for the training set\n",
    "    freq_mag = np.sum((bow_mag > 0) * 1, axis = 0)\n",
    "    idf_mag = np.log((n_videos + 1.0) / (freq_mag + 1.0))\n",
    "    bow_mag = bow_mag * idf_mag\n",
    "    \n",
    "    freq_ang = np.sum((bow_ang > 0) * 1, axis = 0)\n",
    "    idf_ang = np.log((n_videos + 1.0) / (freq_ang + 1.0))\n",
    "    bow_ang = bow_ang * idf_ang\n",
    "    #print(\"idf_mag\")\n",
    "    #print(idf_mag)\n",
    "    # save idf_mag to disk\n",
    "    pickle.dump(idf_mag, open(os.path.join(idfpath,\"idf_mag.pkl\"), \"wb\"))\n",
    "    pickle.dump(idf_ang, open(os.path.join(idfpath,\"idf_ang.pkl\"), \"wb\"))\n",
    "    print(\"Saved IDF weights to disk.\")\n",
    "    \n",
    "    # form the training dataframe\n",
    "    bow_mag = pd.DataFrame(bow_mag, index=vids_list)\n",
    "    bow_ang = pd.DataFrame(bow_ang, index=vids_list)\n",
    "    return bow_mag, bow_ang\n",
    "    \n",
    "    \n",
    "# Form a dataframe using extracted features kept in feats_data_dict by finding the \n",
    "# assignment to one of the centroids.\n",
    "# feats_data_dict: {'filename':[array(2,16,12), array(2,16,12), ....]}\n",
    "def create_bovw_testdf(feats_data_dict, kmeans_mag, kmeans_ang, \\\n",
    "                       mag_min, mag_max, ang_min, ang_max, idfpath):\n",
    "    clusters_mag = kmeans_mag.cluster_centers_\n",
    "    clusters_ang = kmeans_ang.cluster_centers_\n",
    "    vids_list = feats_data_dict.keys()\n",
    "    n_videos = len(vids_list)\n",
    "    \n",
    "    # Create a dataframe of size n_videos X n_clusters\n",
    "    print(\"Make bow vector for each frame\")\n",
    "    bow_mag = np.zeros((n_videos, clusters_mag.shape[0]))\n",
    "    bow_ang = np.zeros((n_videos, clusters_ang.shape[0]))\n",
    "    \n",
    "    print(\"Shape of bow_mag : {}\".format(bow_mag.shape))\n",
    "    print(\"Shape of bow_ang : {}\".format(bow_ang.shape))\n",
    "    \n",
    "    # Make bow vectors for all videos.\n",
    "    for video_index, video in enumerate(vids_list):\n",
    "        # Read the features from the dictionary and get the\n",
    "        frames_feats = feats_data_dict[video]\n",
    "        mag, ang = [], []\n",
    "        \n",
    "        # feat is an array(2,16,12)\n",
    "        mag = [feat[0,...].ravel() for feat in frames_feats]\n",
    "        ang = [feat[1,...].ravel() for feat in frames_feats]\n",
    "        mag = np.array(mag)  # (nFlowFrames, 192)\n",
    "        ang = np.array(ang)\n",
    "        # change inf values to 0\n",
    "        mag[np.isinf(mag)] = 0\n",
    "        ang[np.isinf(ang)] = 0\n",
    "            \n",
    "        ##### Normalize\n",
    "        mag = (mag - mag_min)/(mag_max - mag_min)\n",
    "        ang = (ang - ang_min)/(ang_max - ang_min)\n",
    "        # find cluster centroid assignments for all points\n",
    "        # returns a tuple, with first element having ids of the cluster centroid \n",
    "        # to which the row i belongs to. Second element is the distance between \n",
    "        # the nearest code and the ith row.\n",
    "        # visual_word_ids is a 1D array\n",
    "        print(\"Shape mag : {} :: Shape clusters : {}\".format(mag.shape, clusters_mag.shape))\n",
    "        word_ids_mag = vq(mag, clusters_mag)[0]  # ignoring the distances in [1]\n",
    "        word_ids_ang = vq(ang, clusters_ang)[0]  # ignoring the distances in [1]\n",
    "        for word_id in word_ids_mag:\n",
    "            bow_mag[video_index, word_id] += 1\n",
    "               \n",
    "        for word_id in word_ids_ang:\n",
    "            bow_ang[video_index, word_id] += 1\n",
    "        \n",
    "        print(\"Done video {} : {}\".format(video_index, video))\n",
    "\n",
    "    ##print(\"Applying TF-IDF weighting\")\n",
    "    # This is applicable for only the training set\n",
    "    # For validation/test set, the idf will be same as for the training set\n",
    "    # load idf_mag from disk\n",
    "    idf_mag = pickle.load(open(os.path.join(idfpath,\"idf_mag.pkl\"), \"rb\"))\n",
    "    idf_ang = pickle.load(open(os.path.join(idfpath,\"idf_ang.pkl\"), \"rb\"))\n",
    "    print(\"Loaded IDF weights from disk.\")\n",
    "    bow_mag = bow_mag * idf_mag\n",
    "    bow_ang = bow_ang * idf_ang\n",
    "    \n",
    "    # form the test/validation dataframe\n",
    "    bow_mag = pd.DataFrame(bow_mag, index=vids_list)\n",
    "    bow_ang = pd.DataFrame(bow_ang, index=vids_list)\n",
    "    return bow_mag, bow_ang     # return the test dataframes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
